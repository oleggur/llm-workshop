{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_url = 'https://github.com/DataTalksClub/llm-zoomcamp/raw/main/04-monitoring/data/results-gpt4o-mini.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = f'{github_url}?raw=1'\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_llm</th>\n",
       "      <th>answer_orig</th>\n",
       "      <th>document</th>\n",
       "      <th>question</th>\n",
       "      <th>course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You can sign up for the course by visiting the...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Where can I sign up for the course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You can sign up using the link provided in the...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Can you provide a link to sign up?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes, there is an FAQ for the Machine Learning ...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Is there an FAQ for this Machine Learning course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The context does not provide any specific info...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Does this course have a GitHub repository for ...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To structure your questions and answers for th...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>How can I structure my questions and answers f...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>An alternative way to load the data using the ...</td>\n",
       "      <td>Above users showed how to load the dataset dir...</td>\n",
       "      <td>8d209d6d</td>\n",
       "      <td>What is an alternative way to load the data us...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>You can directly download the dataset from Git...</td>\n",
       "      <td>Above users showed how to load the dataset dir...</td>\n",
       "      <td>8d209d6d</td>\n",
       "      <td>How can I directly download the dataset from G...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>You can fetch data for homework using the `req...</td>\n",
       "      <td>Above users showed how to load the dataset dir...</td>\n",
       "      <td>8d209d6d</td>\n",
       "      <td>Could you share a method to fetch data for hom...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>If the status code is 200 when downloading dat...</td>\n",
       "      <td>Above users showed how to load the dataset dir...</td>\n",
       "      <td>8d209d6d</td>\n",
       "      <td>What should I do if the status code is 200 whe...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>If the file download fails when using the requ...</td>\n",
       "      <td>Above users showed how to load the dataset dir...</td>\n",
       "      <td>8d209d6d</td>\n",
       "      <td>What does the code using the requests library ...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            answer_llm  \\\n",
       "0    You can sign up for the course by visiting the...   \n",
       "1    You can sign up using the link provided in the...   \n",
       "2    Yes, there is an FAQ for the Machine Learning ...   \n",
       "3    The context does not provide any specific info...   \n",
       "4    To structure your questions and answers for th...   \n",
       "..                                                 ...   \n",
       "295  An alternative way to load the data using the ...   \n",
       "296  You can directly download the dataset from Git...   \n",
       "297  You can fetch data for homework using the `req...   \n",
       "298  If the status code is 200 when downloading dat...   \n",
       "299  If the file download fails when using the requ...   \n",
       "\n",
       "                                           answer_orig  document  \\\n",
       "0    Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "1    Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "2    Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "3    Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "4    Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "..                                                 ...       ...   \n",
       "295  Above users showed how to load the dataset dir...  8d209d6d   \n",
       "296  Above users showed how to load the dataset dir...  8d209d6d   \n",
       "297  Above users showed how to load the dataset dir...  8d209d6d   \n",
       "298  Above users showed how to load the dataset dir...  8d209d6d   \n",
       "299  Above users showed how to load the dataset dir...  8d209d6d   \n",
       "\n",
       "                                              question  \\\n",
       "0                  Where can I sign up for the course?   \n",
       "1                   Can you provide a link to sign up?   \n",
       "2    Is there an FAQ for this Machine Learning course?   \n",
       "3    Does this course have a GitHub repository for ...   \n",
       "4    How can I structure my questions and answers f...   \n",
       "..                                                 ...   \n",
       "295  What is an alternative way to load the data us...   \n",
       "296  How can I directly download the dataset from G...   \n",
       "297  Could you share a method to fetch data for hom...   \n",
       "298  What should I do if the status code is 200 whe...   \n",
       "299  What does the code using the requests library ...   \n",
       "\n",
       "                        course  \n",
       "0    machine-learning-zoomcamp  \n",
       "1    machine-learning-zoomcamp  \n",
       "2    machine-learning-zoomcamp  \n",
       "3    machine-learning-zoomcamp  \n",
       "4    machine-learning-zoomcamp  \n",
       "..                         ...  \n",
       "295  machine-learning-zoomcamp  \n",
       "296  machine-learning-zoomcamp  \n",
       "297  machine-learning-zoomcamp  \n",
       "298  machine-learning-zoomcamp  \n",
       "299  machine-learning-zoomcamp  \n",
       "\n",
       "[300 rows x 5 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer,util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oleg/llm-workshop/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"multi-qa-mpnet-base-dot-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_llm = df.iloc[0].answer_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_orig = df.iloc[0].answer_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = model.encode(answer_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(-0.42244673)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1\n",
    "answer: np.float32(-0.42244673)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_and_orig_answers = df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = llm_and_orig_answers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dot_similarity(row):\n",
    "    answer_llm_emb = model.encode(row['answer_llm'])\n",
    "    answer_orig_emb = model.encode(row['answer_orig'])\n",
    "\n",
    "    return util.dot_score(answer_llm_emb, answer_orig_emb).cpu().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:05<00:00, 53.97it/s]\n"
     ]
    }
   ],
   "source": [
    "evaluations = []\n",
    "\n",
    "for row in tqdm(llm_and_orig_answers):\n",
    "    dot_similarity = compute_dot_similarity(row)\n",
    "    evaluations.append(dot_similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[17.5159969329834]],\n",
       " [[13.418407440185547]],\n",
       " [[25.313249588012695]],\n",
       " [[12.147418975830078]],\n",
       " [[18.747730255126953]],\n",
       " [[33.97039794921875]],\n",
       " [[30.25170135498047]],\n",
       " [[29.521587371826172]],\n",
       " [[35.27220153808594]],\n",
       " [[27.75175666809082]],\n",
       " [[32.3447151184082]],\n",
       " [[31.441844940185547]],\n",
       " [[36.38072967529297]],\n",
       " [[33.34051513671875]],\n",
       " [[30.60616111755371]],\n",
       " [[32.50304412841797]],\n",
       " [[29.674449920654297]],\n",
       " [[24.353464126586914]],\n",
       " [[20.132463455200195]],\n",
       " [[23.995466232299805]],\n",
       " [[30.880273818969727]],\n",
       " [[32.69243621826172]],\n",
       " [[30.04916763305664]],\n",
       " [[16.078166961669922]],\n",
       " [[31.79641342163086]],\n",
       " [[37.980018615722656]],\n",
       " [[20.83904266357422]],\n",
       " [[32.612857818603516]],\n",
       " [[38.89421081542969]],\n",
       " [[34.05183410644531]],\n",
       " [[28.26387596130371]],\n",
       " [[27.12483024597168]],\n",
       " [[23.975265502929688]],\n",
       " [[26.340139389038086]],\n",
       " [[18.658123016357422]],\n",
       " [[25.016395568847656]],\n",
       " [[21.10113525390625]],\n",
       " [[33.7267951965332]],\n",
       " [[29.340351104736328]],\n",
       " [[28.654495239257812]],\n",
       " [[29.60858154296875]],\n",
       " [[30.810733795166016]],\n",
       " [[33.331199645996094]],\n",
       " [[26.220483779907227]],\n",
       " [[26.55007553100586]],\n",
       " [[13.148599624633789]],\n",
       " [[12.962546348571777]],\n",
       " [[12.27560806274414]],\n",
       " [[9.974443435668945]],\n",
       " [[10.883928298950195]],\n",
       " [[29.845073699951172]],\n",
       " [[32.36178970336914]],\n",
       " [[22.187175750732422]],\n",
       " [[30.2689266204834]],\n",
       " [[25.09187889099121]],\n",
       " [[32.74278259277344]],\n",
       " [[28.220989227294922]],\n",
       " [[27.274974822998047]],\n",
       " [[24.208637237548828]],\n",
       " [[22.56890106201172]],\n",
       " [[19.76744842529297]],\n",
       " [[18.679332733154297]],\n",
       " [[20.422313690185547]],\n",
       " [[22.051319122314453]],\n",
       " [[18.188011169433594]],\n",
       " [[28.455883026123047]],\n",
       " [[25.919700622558594]],\n",
       " [[23.33233642578125]],\n",
       " [[22.205936431884766]],\n",
       " [[28.296293258666992]],\n",
       " [[39.23054504394531]],\n",
       " [[36.758506774902344]],\n",
       " [[31.91389274597168]],\n",
       " [[31.202856063842773]],\n",
       " [[36.913047790527344]],\n",
       " [[30.514198303222656]],\n",
       " [[36.26146697998047]],\n",
       " [[27.39754867553711]],\n",
       " [[37.79279708862305]],\n",
       " [[23.297685623168945]],\n",
       " [[34.25257873535156]],\n",
       " [[34.55061340332031]],\n",
       " [[30.316455841064453]],\n",
       " [[35.703514099121094]],\n",
       " [[31.01252555847168]],\n",
       " [[35.45961380004883]],\n",
       " [[35.07576370239258]],\n",
       " [[35.42982864379883]],\n",
       " [[29.881174087524414]],\n",
       " [[30.0371150970459]],\n",
       " [[31.24797821044922]],\n",
       " [[29.893943786621094]],\n",
       " [[28.52552032470703]],\n",
       " [[31.754608154296875]],\n",
       " [[32.59006118774414]],\n",
       " [[39.476016998291016]],\n",
       " [[34.973724365234375]],\n",
       " [[28.725086212158203]],\n",
       " [[30.684101104736328]],\n",
       " [[37.26410675048828]],\n",
       " [[35.62683868408203]],\n",
       " [[33.20292663574219]],\n",
       " [[25.320384979248047]],\n",
       " [[32.18891143798828]],\n",
       " [[22.518665313720703]],\n",
       " [[30.81064224243164]],\n",
       " [[37.47418212890625]],\n",
       " [[27.12754249572754]],\n",
       " [[27.558427810668945]],\n",
       " [[33.07744598388672]],\n",
       " [[25.819046020507812]],\n",
       " [[35.047584533691406]],\n",
       " [[34.91013717651367]],\n",
       " [[35.8629264831543]],\n",
       " [[35.664615631103516]],\n",
       " [[23.890949249267578]],\n",
       " [[26.650798797607422]],\n",
       " [[19.036319732666016]],\n",
       " [[23.732627868652344]],\n",
       " [[36.686492919921875]],\n",
       " [[23.63224983215332]],\n",
       " [[26.224361419677734]],\n",
       " [[28.33197784423828]],\n",
       " [[28.20587921142578]],\n",
       " [[29.783937454223633]],\n",
       " [[27.143463134765625]],\n",
       " [[14.999910354614258]],\n",
       " [[18.169992446899414]],\n",
       " [[18.228649139404297]],\n",
       " [[20.363128662109375]],\n",
       " [[5.448554515838623]],\n",
       " [[5.93248176574707]],\n",
       " [[7.870975494384766]],\n",
       " [[4.547921657562256]],\n",
       " [[5.385084629058838]],\n",
       " [[27.71397590637207]],\n",
       " [[20.700138092041016]],\n",
       " [[27.3294677734375]],\n",
       " [[16.532575607299805]],\n",
       " [[19.901351928710938]],\n",
       " [[31.073856353759766]],\n",
       " [[29.63745880126953]],\n",
       " [[28.450876235961914]],\n",
       " [[24.88910675048828]],\n",
       " [[26.597518920898438]],\n",
       " [[26.664060592651367]],\n",
       " [[33.77531814575195]],\n",
       " [[28.765796661376953]],\n",
       " [[19.707881927490234]],\n",
       " [[17.30651092529297]],\n",
       " [[34.35748291015625]],\n",
       " [[30.779722213745117]],\n",
       " [[30.17049217224121]],\n",
       " [[27.35458755493164]],\n",
       " [[32.209922790527344]],\n",
       " [[26.880233764648438]],\n",
       " [[28.167715072631836]],\n",
       " [[29.97623634338379]],\n",
       " [[28.072681427001953]],\n",
       " [[31.957592010498047]],\n",
       " [[30.330577850341797]],\n",
       " [[29.30562400817871]],\n",
       " [[27.504318237304688]],\n",
       " [[27.409873962402344]],\n",
       " [[26.012462615966797]],\n",
       " [[31.341299057006836]],\n",
       " [[29.248130798339844]],\n",
       " [[34.05439376831055]],\n",
       " [[29.529327392578125]],\n",
       " [[27.14474868774414]],\n",
       " [[26.03489112854004]],\n",
       " [[31.496734619140625]],\n",
       " [[32.25983810424805]],\n",
       " [[21.9324893951416]],\n",
       " [[30.880067825317383]],\n",
       " [[39.09270477294922]],\n",
       " [[32.14210510253906]],\n",
       " [[25.34588623046875]],\n",
       " [[23.977584838867188]],\n",
       " [[27.3140869140625]],\n",
       " [[30.8774356842041]],\n",
       " [[28.47052764892578]],\n",
       " [[28.86775779724121]],\n",
       " [[28.17321014404297]],\n",
       " [[27.83441925048828]],\n",
       " [[33.21150207519531]],\n",
       " [[27.782203674316406]],\n",
       " [[28.15019416809082]],\n",
       " [[27.548816680908203]],\n",
       " [[29.624217987060547]],\n",
       " [[28.46662139892578]],\n",
       " [[27.704877853393555]],\n",
       " [[27.517038345336914]],\n",
       " [[26.017349243164062]],\n",
       " [[16.815933227539062]],\n",
       " [[29.1818790435791]],\n",
       " [[30.13019371032715]],\n",
       " [[27.391754150390625]],\n",
       " [[28.571136474609375]],\n",
       " [[21.442026138305664]],\n",
       " [[29.071903228759766]],\n",
       " [[27.174827575683594]],\n",
       " [[26.663850784301758]],\n",
       " [[26.15339469909668]],\n",
       " [[29.611270904541016]],\n",
       " [[27.712764739990234]],\n",
       " [[17.301193237304688]],\n",
       " [[25.073745727539062]],\n",
       " [[26.10517692565918]],\n",
       " [[15.056326866149902]],\n",
       " [[32.224449157714844]],\n",
       " [[26.998760223388672]],\n",
       " [[24.001840591430664]],\n",
       " [[30.299421310424805]],\n",
       " [[31.251951217651367]],\n",
       " [[24.93145751953125]],\n",
       " [[27.136260986328125]],\n",
       " [[20.048168182373047]],\n",
       " [[22.204578399658203]],\n",
       " [[18.398670196533203]],\n",
       " [[23.471607208251953]],\n",
       " [[23.656587600708008]],\n",
       " [[20.096872329711914]],\n",
       " [[27.785179138183594]],\n",
       " [[23.72188377380371]],\n",
       " [[29.476564407348633]],\n",
       " [[31.92364501953125]],\n",
       " [[27.78656005859375]],\n",
       " [[25.28249168395996]],\n",
       " [[21.090362548828125]],\n",
       " [[34.241966247558594]],\n",
       " [[34.56610107421875]],\n",
       " [[35.932586669921875]],\n",
       " [[22.799602508544922]],\n",
       " [[33.241451263427734]],\n",
       " [[19.981958389282227]],\n",
       " [[22.636579513549805]],\n",
       " [[24.131187438964844]],\n",
       " [[23.12018585205078]],\n",
       " [[11.905020713806152]],\n",
       " [[32.21834945678711]],\n",
       " [[29.581180572509766]],\n",
       " [[22.276996612548828]],\n",
       " [[26.25490951538086]],\n",
       " [[18.278995513916016]],\n",
       " [[33.623138427734375]],\n",
       " [[29.7764949798584]],\n",
       " [[30.866945266723633]],\n",
       " [[26.5390682220459]],\n",
       " [[26.438840866088867]],\n",
       " [[23.82001495361328]],\n",
       " [[27.36067771911621]],\n",
       " [[29.6370792388916]],\n",
       " [[31.316280364990234]],\n",
       " [[20.20751190185547]],\n",
       " [[34.52055740356445]],\n",
       " [[33.35490798950195]],\n",
       " [[28.474090576171875]],\n",
       " [[27.69429588317871]],\n",
       " [[21.4862117767334]],\n",
       " [[29.00383758544922]],\n",
       " [[26.534305572509766]],\n",
       " [[28.94831085205078]],\n",
       " [[27.005245208740234]],\n",
       " [[24.34091567993164]],\n",
       " [[21.608489990234375]],\n",
       " [[33.209815979003906]],\n",
       " [[31.647544860839844]],\n",
       " [[30.631366729736328]],\n",
       " [[25.525129318237305]],\n",
       " [[31.805736541748047]],\n",
       " [[34.97617721557617]],\n",
       " [[29.750328063964844]],\n",
       " [[28.022010803222656]],\n",
       " [[24.982284545898438]],\n",
       " [[34.44129180908203]],\n",
       " [[33.40549850463867]],\n",
       " [[30.95248031616211]],\n",
       " [[25.195037841796875]],\n",
       " [[29.61396598815918]],\n",
       " [[31.487974166870117]],\n",
       " [[29.713956832885742]],\n",
       " [[28.34174346923828]],\n",
       " [[28.79732894897461]],\n",
       " [[28.471725463867188]],\n",
       " [[38.85507583618164]],\n",
       " [[35.33558654785156]],\n",
       " [[13.90458869934082]],\n",
       " [[38.24656295776367]],\n",
       " [[30.029457092285156]],\n",
       " [[33.363075256347656]],\n",
       " [[25.712203979492188]],\n",
       " [[32.535797119140625]],\n",
       " [[31.4112548828125]],\n",
       " [[30.52425765991211]],\n",
       " [[34.00178527832031]],\n",
       " [[33.690860748291016]],\n",
       " [[34.49153137207031]],\n",
       " [[27.538349151611328]],\n",
       " [[18.414098739624023]]]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the 75th percentile\n",
    "percentile_75 = np.percentile(evaluations, 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(31.6743106842041)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentile_75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2\n",
    "np.float64(31.6743106842041)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarity(row):\n",
    "    answer_llm_emb = model.encode(row['answer_llm'])\n",
    "    norm = np.sqrt((answer_llm_emb * answer_llm_emb).sum())\n",
    "    norm_llm = answer_llm_emb / norm\n",
    "\n",
    "    answer_orig_emb = model.encode(row['answer_orig'])\n",
    "    norm = np.sqrt((answer_orig_emb * answer_orig_emb).sum())\n",
    "    norm_orig = answer_orig_emb / norm\n",
    "\n",
    "\n",
    "    return util.dot_score(norm_llm, norm_orig).cpu().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:05<00:00, 53.04it/s]\n"
     ]
    }
   ],
   "source": [
    "evaluations_normalized = []\n",
    "\n",
    "for row in tqdm(llm_and_orig_answers):\n",
    "    cosine_similarity = compute_cosine_similarity(row)\n",
    "    evaluations_normalized.append(cosine_similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_percentile_75 = np.percentile(evaluations_normalized, 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8362348079681396)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_percentile_75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3\n",
    "np.float64(0.8362348079681396)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "rouge_scorer = Rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = rouge_scorer.get_scores(llm_and_orig_answers[10]['answer_llm'], llm_and_orig_answers[10]['answer_orig'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.45454545454545453,\n",
       "  'p': 0.45454545454545453,\n",
       "  'f': 0.45454544954545456},\n",
       " 'rouge-2': {'r': 0.21621621621621623,\n",
       "  'p': 0.21621621621621623,\n",
       "  'f': 0.21621621121621637},\n",
       " 'rouge-l': {'r': 0.3939393939393939,\n",
       "  'p': 0.3939393939393939,\n",
       "  'f': 0.393939388939394}}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4\n",
    "  'f': 0.45454544954545456},"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
